{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20159fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:18: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:18: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-3-981f40a91afe>:18: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is () :\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Samples Of Rohit\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting Samples Complete\n",
      "Wait for 10 Second....\n",
      "Collecting Samples Of Rahul\n",
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "#STEP 1 CREATE DATA FOR TRAINING THE MODEL\n",
    "#Create Training Data\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# load haarcascade face classifier\n",
    "face_classifier = cv2.CascadeClassifier( \"haarcascade_frontalface_default.xml\" )\n",
    " \n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is () :\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "        \n",
    "    return cropped_face\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "def collectingFaces(path, count):\n",
    "    # Initialize Webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if face_extractor(frame) is not None:\n",
    "            count += 1\n",
    "            face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "            # Save file in specified directory with unique name\n",
    "            file_name_path = path + str(count) + '.jpg'\n",
    "            cv2.imwrite(file_name_path, face)\n",
    "        \n",
    "            # Put count on images and display live count\n",
    "            cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "        else:\n",
    "            print(\"Face not found\")\n",
    "            pass\n",
    "        if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "            break\n",
    "        \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()      \n",
    "    print(\"Collecting Samples Complete\")\n",
    "\n",
    "\n",
    "i = 0 \n",
    "j = 0\n",
    "\n",
    "print(\"Collecting Samples Of Rohit\")\n",
    "collectingFaces(\"./faces/rohit/\", i)\n",
    "print(\"Wait for 10 Second....\")\n",
    "time.sleep(10)\n",
    "\n",
    "print(\"Collecting Samples Of Rahul\")\n",
    "collectingFaces(\"./faces/rahul/\", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a7298f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rohit's Model trained sucessefully\n",
      "Rahul's Model trained sucessefully\n"
     ]
    }
   ],
   "source": [
    "# STEP 2 TRAIN MODEL FROM THE CREATED TRAINING DATA\n",
    "#Train Model\n",
    "from sys import path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path  import isfile, join\n",
    "# Get training data we previously made\n",
    "def trainModel(path):\n",
    "    \n",
    "    data_path = path\n",
    "    onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "    # Create arrays from training data and labels\n",
    "    Training_Data, Labels = [], []\n",
    "\n",
    "    # Open training images in our datapath\n",
    "    # Create a numpy array for training data\n",
    "    for i, files in enumerate(onlyfiles):\n",
    "        image_path = data_path + onlyfiles[i]\n",
    "        images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "        Labels.append(i)\n",
    "    \n",
    "    # Create a numpy array for both training data and labels\n",
    "    Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "    # Initialize facial recognizer\n",
    "    # model = cv2.face.createLBPHFaceRecognizer()\n",
    "    # NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "    # pip install opencv-contrib-python\n",
    "    # model = cv2.createLBPHFaceRecognizer()\n",
    "    \n",
    "    model = cv2.face_LBPHFaceRecognizer.create()\n",
    "    # Let's train our model \n",
    "    model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "    return model\n",
    "  \n",
    "\n",
    "\n",
    "rohit_model = trainModel(\"./faces/rohit/\")\n",
    "print(\"Rohit's Model trained sucessefully\")\n",
    "rahul_model = trainModel(\"./faces/rahul/\")\n",
    "print(\"Rahul's Model trained sucessefully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7cb4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:20: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:20: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-6-c75f1cbf7468>:20: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is () :\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pywhatkit\n",
    "\n",
    "def confidence(results, image):\n",
    "    if results[1] < 500 :\n",
    "        confidence = int( 100 * (1 - (results[1])/400) )\n",
    "        display_string = str(confidence) + '% Confident it is User'\n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "    return confidence\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is () :\n",
    "        return img, []\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "\n",
    "def sendingmail(to, text):\n",
    "    import smtplib  \n",
    "    server = smtplib.SMTP_SSL( \"smtp.gmail.com\", 465 )\n",
    "    server.login( \"1824004062.rohit@gmail.com\", \"1824004062\" )\n",
    "    server.sendmail( \"1824004009rahulkashyap@gmail.com\", to, text)\n",
    "    server.quit()\n",
    "\n",
    "def get_time():\n",
    "    import time\n",
    "    t = time.localtime()\n",
    "    hour = int(time.strftime(\"%H\", t))\n",
    "    min = int(time.strftime(\"%M\", t)) +1 \n",
    "    return hour, min\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    image, face = face_detector(frame)\n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        rohit_results = rohit_model.predict(face)\n",
    "        rahul_results = rahul_model.predict(face)\n",
    "        \n",
    "        rohit_confidence = confidence(rohit_results, image)\n",
    "        rahul_confidence = confidence(rahul_results, image)\n",
    "\n",
    "        if  rohit_confidence > 50:\n",
    "            cv2.putText(image, \"Rohit Vishwakarma \", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            cv2.waitKey(3000)\n",
    "            cv2.destroyAllWindows()\n",
    "            sendingmail(\"1824004062.rohit@gmail.com\", \"Hey cage!!,  your face detected in camera!\")\n",
    "            os.system(\"aws ec2 run-instances --image-id ami-0ad704c126371a549 --instance-type t2.micro\")\n",
    "            os.system(\"aws ec2 create-volume --volume-type gp2 --size 5 --region ap-south-1 --availability-zone ap-south-1a\")\n",
    "            i = input(\"Enter VolumeID: \")\n",
    "            j = input(\"Enter InstanceID: \")\n",
    "            command = \"aws ec2 attach-volume --volume-id \" + i + \" --instance-id \" + j + \" --device /dev/sdf --region ap-south-1\"\n",
    "            os.system(command)\n",
    "            break\n",
    "         \n",
    "        elif rahul_confidence > 40:\n",
    "            cv2.putText(image, \"Rahul Kashyap\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            cv2.waitKey(3000)\n",
    "            cv2.destroyAllWindows()\n",
    "            sendingmail(\"1824004062.rohit@gmail.com\", \"Hey cage!!,  your face detected in camera!\")\n",
    "            pywhatkit.sendwhatmsg_instantly(\"+919033946703\", \"Helloo!!, This is from Model?\")\n",
    "\n",
    "\n",
    "        else:    \n",
    "            cv2.putText(image, \"Rcognizing Face...\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "        \n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found!\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"Looking For Face...\", (220, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1904d13e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9b9e9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0aa0d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
